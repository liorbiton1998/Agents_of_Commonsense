# -*- coding: utf-8 -*-
"""multi_agents.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15A7zrTWK7xqGgZf8mMSO2FbVpD75Ls4b

# Imports
"""

! pip install -U datasets

!pip install langchain langchain-google-genai wikipedia langchain-openai langgraph langchain-community

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
import os
from langchain.agents import initialize_agent
from langchain.agents.agent_types import AgentType
from langchain.tools import tool
from langchain.utilities import WikipediaAPIWrapper
from langchain_core.messages import HumanMessage, BaseMessage, AIMessage
from typing import TypedDict, List, Dict, Any
from langgraph.graph import StateGraph, END
from IPython.display import Image, display
import json
from pathlib import Path
from datasets import load_dataset
import re
import glob
from collections import defaultdict, Counter

from google.colab import drive
drive.mount('/content/drive')

"""## API Keys"""

os.environ["OPENAI_API_KEY"] = "************"
os.environ["GOOGLE_API_KEY"] = "************"
os.environ["OPENROUTER_API_KEY"] = "************"

def init_llm(provider="gemini", model=None, temperature=0.7):
    if provider == "gemini":
        key = os.getenv("GOOGLE_API_KEY")
        if not key:
            raise ValueError("Set GOOGLE_API_KEY")
        model = model or "gemini-1.5-flash"
        return ChatGoogleGenerativeAI(model=model, temperature=temperature, google_api_key=key)

    elif provider == "gpt":
        key = os.getenv("OPENAI_API_KEY")
        if not key:
            raise ValueError("Set OPENAI_API_KEY")
        model = model or "gpt-3.5-turbo"
        return ChatOpenAI(model=model, temperature=temperature, openai_api_key=key)

    elif provider == "openrouter":
        key = os.getenv("OPENROUTER_API_KEY")
        if not key:
            raise ValueError("Set OPENROUTER_API_KEY")
        model = model or "google/gemini-flash-1.5-8b"
        return ChatOpenAI(
            model=model,
            temperature=temperature,
            api_key=key,
            base_url="https://openrouter.ai/api/v1",  # Important for routing to OpenRouter
        )

    raise ValueError("Choose 'gemini' or 'gpt'")

"""# Configuration"""

def build_experiment_id(max_rounds, tie_break_strategy, strongest_agent, agent_llms, order):
    parts = [
        f"MaxRound={max_rounds}",
        f"Stratgey={tie_break_strategy}",
        f"StrongestAgent={strongest_agent}",
        "Agents=" + "-".join(agent_llms.keys()),
        "Order=" + "-".join(order),
    ]
    return "_".join(parts)


def create_save_dir(exp_id):
    save_dir = Path(exp_id)
    save_dir.mkdir(parents=True, exist_ok=True)
    return save_dir

AGENTS = {
    "Retriever": {
    "style": (
        "You are a well-informed research assistant who always consults reliable sources. "
        "Refer to what your previous friends said — do you agree with them? Then answer. "
        "You can use tools like Wikipedia to find facts before answering. You are encouraged to use the tools. "
        "Your answers should be fact-driven. If supporting facts are retrieved, quote or paraphrase them. "


        "IMPORTANT: At the end, return your final reasoning and answer INSIDE a JSON block using this exact format:\n"
        "```json\n"
        "{\n"
        '  "action": "Final Answer",\n'
        '  "action_input": "<your reasoning here>\\nAnswer: <your chosen letter A–E>"\n'
        "}\n"
        "```"
    ),
        "use_retrieval": True
    },
    "Reasoner": {
        "style": (
            "You are a logical analyst who solves problems by breaking them down step by step. "
            "Your goal is to evaluate each option carefully, eliminate the unlikely ones, and explain "
            "your reasoning at each stage. Always follow a structured thought process. Never skip steps."
            "Refer to what you previous friends said, do you agree with them?"
            "Then answer step by step."
        ),
        "use_retrieval": False
    },
    "Intuitive": {
        "style": (
            "You are a critical thinking expert who reviews and challenges analyses."
            "Your job is to identify potential flaws in reasoning, consider alternative perspectives, and provide constructive criticism. "
            "You should point out any weaknesses in the analysis and suggest improvements or alternative approaches. choose the correct answer"
        ),
        "use_retrieval": False
    },
     "Critical": {
        "style": (
            "You are a fast, instinctive thinker who relies on gut feeling, everyday knowledge, "
            "and common sense. You prefer short, confident answers based on general life experience and intuition."
            "Refer to what you previous friends said, do you agree with them?"
            "Then answer."
            "Don’t overthink - go with what feels right. "
        ),
        "use_retrieval": False
    },
    "Judge": {
    "style": (
            "You give the final decision. Carefully read the full discussion. "
            "Summarize the main points from each teammate and explain whose reasoning makes the most sense. "
            "Then select the final answer based on the strongest argument."
    ),
    "use_retrieval": False
    }
}

"""# Utility Functions"""

class QAState(TypedDict, total=False):
    messages: List[BaseMessage]
    agent_order: List[str]
    final_answers: Dict[str, str]
    round_num: int
    retriever_tool_usage: List[str]

def make_branching_logic(tie_break_strategy, strongest_agent, max_rounds):
    def branching_logic(state):
        return choose_next_state(
            state,
            rounds_done=state["round_num"],
            max_rounds=max_rounds,
            tie_break_strategy=tie_break_strategy,
            strongest_agent=strongest_agent
        )
    return branching_logic

wiki = WikipediaAPIWrapper()

@tool
def wiki_search(query: str) -> str:
    """Look up information on Wikipedia."""
    return wiki.run(query)

class LoggingRetrieverWrapper:
    def __init__(self, agent_executor):
        self.agent_executor = agent_executor
        self.last_tools_used = []

    def run(self, prompt_dict):
        result = self.agent_executor.invoke(prompt_dict, return_only_outputs=False)

        # Save tools used (for logging)
        self.last_tools_used = [
            {
                "tool": action.tool,
                "input": str(action.tool_input),
                "observation": str(observation)[:100]  # Optional truncation
            }
            for action, observation in result.get("intermediate_steps", [])
            if hasattr(action, "tool") and hasattr(action, "tool_input")
        ]

        # Return just the final output as usual
        return result["output"]

def create_agent(llm, agent_name):
    agent_config = AGENTS.get(agent_name, AGENTS[agent_name])
    style = agent_config["style"]
    use_retrieval = agent_config["use_retrieval"]
    if use_retrieval:
        agent_executor = initialize_agent(
            tools=[wiki_search],
            llm=llm,
            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
            verbose=True,
            return_intermediate_steps=True
        )
        return LoggingRetrieverWrapper(agent_executor)

    else:
        class SimpleAgent:
            def run(self, prompt_dict):
                return llm.invoke(prompt_dict["input"]).content
        return SimpleAgent()

def generate_agent_response(agent_name: str, state: QAState, agent):
    system_prompt = f"""You are {agent_name}.
    Your style: {AGENTS[agent_name]["style"]}

    Read the conversation so far and provide your answer.

    IMPORTANT: Always end your response with the following format:

    Answer: [A–E] CHOOSE ONE OPTION!
    This line MUST appear at the end of your response.
    """
    full_prompt = "\n".join([f"{m.name or 'User'}: {m.content}" for m in state["messages"]])
    response = agent.run({
        "input": full_prompt + "\n\n" + system_prompt,
        "chat_history": state["messages"]
    })

    msg = AIMessage(content=response.strip(), name=agent_name)
    tools_used = getattr(agent, "last_tools_used", [])
    return msg, tools_used

def create_runnable_graph(agent_order, llm_map, make_node_fn, state_type, tie_break_strategy, strongest_agent, max_rounds):
    graph = StateGraph(state_type)
    cached_agents = {
        agent_name: create_agent(llm_map[agent_name], agent_name)
        for agent_name in set(agent_order + ["Judge"])
        if agent_name in llm_map
    }
    for agent_name in agent_order:
        graph.add_node(agent_name, make_node_fn(agent_name, cached_agents[agent_name]))
    graph.set_entry_point(agent_order[0])
    for src, dst in zip(agent_order, agent_order[1:]):
        graph.add_edge(src, dst)

    branch_map = {
        agent_order[0]: agent_order[0],
        END: END
    }
    if tie_break_strategy == "judge":
        branch_map["Judge"] = "Judge"
        if "Judge" not in agent_order:
            agent_name = "Judge"
            graph.add_node(agent_name, make_node_fn(agent_name, cached_agents[agent_name]))
        graph.add_edge("Judge", END)
    branching_logic_fn = make_branching_logic(tie_break_strategy, strongest_agent, max_rounds)
    graph.add_conditional_edges(agent_order[-1], branching_logic_fn, branch_map)

    return graph.compile()

def display_runnable(runnable):
    display(Image(runnable.get_graph().draw_mermaid_png()))

def make_agent_node(agent_name: str, agent):
    def node_fn(state: QAState) -> QAState:
        msg, tools_used = generate_agent_response(agent_name, state, agent)
        updated = dict(state)
        updated["messages"] = state["messages"] + [msg]
        updated["final_answers"] = {**state["final_answers"], agent_name: extract_answer_letter(msg.content)}
        if agent_name == "Retriever" and tools_used:
          updated["retriever_tool_usage"] = tools_used
        if agent_name == state["agent_order"][-1]:
          updated["round_num"] += 1
        if agent_name == "Judge":
          updated["next"] = END
        return updated
    return node_fn


def extract_answer_letter(text: str) -> str:
    patterns = [
        r"(?i)\banswer\b[^A-Ea-e]{0,5}([A-E])\b",
        r"(?i)\bfinal answer\b[^A-Ea-e]{0,5}([A-E])\b",
        r"\b([A-E])\b"
    ]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(1).upper()
    return "?"

def initialize_state(formatted, agent_order: list[str]):
    return {
        "messages": [HumanMessage(content=formatted, name="User")],
        "agent_order": agent_order,
        "final_answers": {},
        "round_num": 0,
        "retriever_tool_usage": []
    }

def choose_next_state(state: QAState, rounds_done: int, max_rounds: int, tie_break_strategy: str, strongest_agent: str = "Reasoner"):
    answers = list(state["final_answers"].values() or [])
    if answers and all(a == answers[0] for a in answers):
        return END

    elif rounds_done >= max_rounds:
        if tie_break_strategy == "strongest":
            state["final_answers"] = {agent: state["final_answers"].get(strongest_agent, "?") for agent in state["agent_order"]}
            return END
        elif tie_break_strategy == "judge":
            return "Judge"
        else:
            return END

    else:
        return state["agent_order"][0]

"""# **Tie-break: "Judge"**
1. The process starts with a question.

2. The Intuitive agent gives its answer.

3. Then the Reasoner responds, seeing Intuitive’s response.

4. Based on branching_logic:

    If they agree → go to __end__.

    If they disagree, and more rounds left → loop back to Intuitive.

    If no more rounds and tie-breaking strategy is "judge" → go to Judge.

5. Judge sees the full history and makes a final call → leads to __end__.

# **Tie-break: "strongest"**
Starts with Intuitive → then Reasoner responds.

If they agree → go to __end__.

If they disagree and rounds remain → loop back to Intuitive for another round.

If they still disagree after max rounds → use Reasoner’s answer (strongest agent) as final → go to __end__.

# Evaluation
"""

_DATA = load_dataset("tau/commonsense_qa", split="validation")

def save_evaluation(idx, question, final_state, correct_answer, options, tie_break_strategy, strongest_agent, save_dir):
    save_dir.mkdir(parents=True, exist_ok=True)
    messages = final_state["messages"]
    agent_order = final_state.get("agent_order", [])
    agents = [a for a in agent_order if a != "Judge"]
    round_count = final_state.get("round_num", 1)

    conversation = [{"name": m.name, "content": m.content} for m in messages]

    agent_answers_by_round = []
    current_round = {}
    for msg in messages:
        if msg.name in agents:
            answer = extract_answer_letter(msg.content)
            current_round[msg.name] = answer
            if len(current_round) == len(agents):
                agent_answers_by_round.append(current_round.copy())
                current_round.clear()

    final_answers = final_state["final_answers"]
    final_agreement = len(set(final_answers.values())) == 1

    if final_agreement:
        final_decision_method = "agreement"
        final_answer = list(final_answers.values())[0]
    elif tie_break_strategy == "strongest":
        final_decision_method = "strongest"
        final_answer = final_answers.get(strongest_agent, "?")
    elif tie_break_strategy == "judge":
        final_decision_method = "judge"
        final_answer = final_answers.get("Judge", "?")
    else:
        final_decision_method = "unknown"
        final_answer = "?"

    accuracy_across_agents = {agent: (ans == correct_answer) for agent, ans in final_answers.items()}
    final_accuracy = (final_answer == correct_answer)


    optional_answers = [f"{label}. {text}" for label, text in options]

    result = {
        "question_id": idx + 1,
        "question": question,
        "optional_answers": optional_answers,
        "conversation": conversation,
        "agent_answers_per_round": agent_answers_by_round,
        "agent_final_answers": final_answers,
        "final_decision_method": final_decision_method,
        "final_selected_answer": final_answer,
        "correct_answer": correct_answer,
        "final_accuracy": final_accuracy,
        "accuracy_across_agents": accuracy_across_agents,
        "final_agreement": final_agreement,
        "round_count": round_count,
        "retriever_tool_usage": final_state.get("retriever_tool_usage", [])
    }
    with open(save_dir / f"q{idx+1:03d}.json", "w") as f:
        json.dump(result, f, indent=2)

    return result

from datasets import load_dataset

def get_questions(dataset, num_questions):
    sliced = dataset.select(range(num_questions))
    questions = []

    for entry in sliced:
        question = entry["question"]
        labels = entry["choices"]["label"]
        texts = entry["choices"]["text"]
        correct_answer = entry["answerKey"]
        options = list(zip(labels, texts))
        formatted = (
            f"{question}\nOptions:\n"
            + "\n".join(f"{label}. {text}" for label, text in options)
        )
        questions.append((question, options, formatted, correct_answer))

    return questions

def run_batch_from_list(runnable, questions, agent_order, tie_break_strategy, strongest_agent, save_dir):
    results = []
    evaluation_logs = []

    for idx, (question, options, formatted, correct_answer) in enumerate(questions):
        try:
            print(f"\n--- Running question {idx+1}/{len(questions)} ---")
            initial_state = initialize_state(formatted, agent_order=agent_order)
            final_state = runnable.invoke(initial_state)

            eval_result = save_evaluation(
                idx=idx,
                question=question,
                final_state=final_state,
                correct_answer=correct_answer,
                options=options,
                tie_break_strategy=tie_break_strategy,
                strongest_agent=strongest_agent,
                save_dir=save_dir
            )

            evaluation_logs.append(eval_result)
            results.append((question, final_state))

        except Exception as e:
            print(f"Error on question {idx+1}: {e}")
            error_log_path = save_dir / "errors.log"
            with open(error_log_path, "a", encoding="utf-8") as f:
                f.write(f"[Question {idx+1}] Error: {repr(e)}\n")
            continue

    # === Compute final accuracy ===
    correct = sum(1 for r in evaluation_logs if r.get("final_accuracy") is True)
    total = len(evaluation_logs)
    accuracy = correct / total if total else 0

    print(f"\n=== Overall Final Accuracy ===")
    print(f"Correct: {correct}/{total}")
    print(f"Accuracy: {accuracy:.2%}")

    return results

"""#  Experiments

Baseline Experiments
"""

EXPERIMENTS = {
    "Exp1": {
        "max_rounds": 0,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Intuitive",
        "agent_order": ["Intuitive"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },

     "Exp2": {
        "max_rounds": 0,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },


    "Exp3": {
        "max_rounds": 0,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Retriever",
        "agent_order": ["Retriever"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },

    "Exp4": {
        "max_rounds": 0,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Intuitive",
        "agent_order": ["Intuitive"],
        "provider": "openrouter",
        "model": "gpt-4o-mini"
    },

     "Exp5": {
        "max_rounds": 0,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner"],
        "provider": "openrouter",
        "model": "gpt-4o-mini"
    },

    "Exp6": {
        "max_rounds": 0,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Retriever",
        "agent_order": ["Retriever"],
        "provider": "openrouter",
        "model": "gpt-4o-mini"
    },
}

"""Multi Agents Experiments"""

EXPERIMENTS = {
    "Exp1": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Intuitive", "Reasoner"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },
    "Exp2": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Reasoner",
        "agent_order": ["Intuitive", "Reasoner"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },
    "Exp3": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Intuitive"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },
    "Exp4": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Intuitive"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },
    "Exp1-gpt": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Intuitive", "Reasoner"],
        "provider": "openrouter",
        "model": "openai/gpt-4o-mini"
    },
    "Exp2-gpt": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Reasoner",
        "agent_order": ["Intuitive", "Reasoner"],
        "provider": "openrouter",
        "model": "openai/gpt-4o-mini"
    },
    "Exp3-gpt": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Intuitive"],
        "provider": "openrouter",
        "model": "openai/gpt-4o-mini"
    },
    "Exp4-gpt": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Intuitive"],
        "provider": "openrouter",
        "model": "openai/gpt-4o-mini"
    },
    "Exp5": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Retriever",
        "agent_order": ["Intuitive", "Reasoner", "Retriever"],
        "provider": "gpt",
        "model": "gpt-4o-mini"
     },
       "Exp6": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Intuitive",
        "agent_order": ["Intuitive", "Reasoner", "Retriever"],
        "provider": "gpt",
        "model": "gpt-4o-mini"
    },
    "Exp7": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Retriever",
        "agent_order": ["Intuitive", "Reasoner", "Retriever"],
        "provider": "gpt",
        "model": "gpt-4o-mini"
    },
    "Exp8": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Intuitive",
        "agent_order": ["Intuitive", "Reasoner", "Retriever"],
        "provider": "gpt",
        "model": "gpt-4o-mini"
    },
    "Exp9": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Critic"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },
    "Exp10": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Critic"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },
    "Exp11": {
        "max_rounds": 3,
        "tie_break_strategy": "judge",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Retriever", "Critic"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },
    "Exp12": {
        "max_rounds": 3,
        "tie_break_strategy": "strongest",
        "strongest_agent": "Reasoner",
        "agent_order": ["Reasoner", "Retriever", "Critic"],
        "provider": "openrouter",
        "model": "google/gemini-2.0-flash-001"
    },

}

"""# Evaluation"""

def compute_final_metrics(save_dir):

    results = glob.glob(os.path.join(save_dir, "q*.json"))

    total_questions = 0
    correct_final = 0
    agent_correct = defaultdict(int)
    agent_total = defaultdict(int)
    agreement_count = 0
    total_rounds = 0
    round_histogram = Counter()

    agent_changes_total = defaultdict(int)
    agent_changes_to_correct = defaultdict(int)
    agent_changes_to_wrong = defaultdict(int)

    retrieval_total_calls = 0
    retrieval_question_count = 0

    questions_all_agents_failed = []
    questions_all_agents_agreed = []

    for file in results:
        with open(file, "r") as f:
            data = json.load(f)

        total_questions += 1
        question_id = data.get("question_id")

        if data.get("final_accuracy", False):
            correct_final += 1

        rounds = data.get("round_count", 0)
        total_rounds += rounds
        round_histogram[rounds] += 1

        all_failed = True
        all_answers = set()

        agent_first_last = defaultdict(lambda: {"first": None, "last": None})
        for round_answers in data.get("agent_answers_per_round", []):
            for agent, ans in round_answers.items():
                if agent_first_last[agent]["first"] is None:
                    agent_first_last[agent]["first"] = ans
                agent_first_last[agent]["last"] = ans

        for agent, acc in data.get("accuracy_across_agents", {}).items():
            agent_total[agent] += 1
            if acc:
                agent_correct[agent] += 1
                all_failed = False

            if agent in data.get("agent_final_answers", {}):
                all_answers.add(data["agent_final_answers"][agent])

            fl = agent_first_last.get(agent)
            if fl and fl["first"] and fl["last"] and fl["first"] != fl["last"]:
                agent_changes_total[agent] += 1
                if fl["last"] == data.get("correct_answer"):
                    agent_changes_to_correct[agent] += 1
                else:
                    agent_changes_to_wrong[agent] += 1

        if all_failed:
            questions_all_agents_failed.append(question_id)

        if len(all_answers) == 1 and len(all_answers) > 0:
            questions_all_agents_agreed.append(question_id)

        if data.get("final_agreement", False):
            agreement_count += 1

        retriever_calls = len(data.get("retriever_tool_usage", []))
        retrieval_total_calls += retriever_calls
        if retriever_calls > 0:
            retrieval_question_count += 1

    final_result = {
        "total_questions": total_questions,
        "overall_final_accuracy": correct_final / total_questions if total_questions else 0,
        "per_agent_accuracy": {
            agent: agent_correct[agent] / agent_total[agent] if agent_total[agent] else 0
            for agent in agent_total
        },
        "agreement_rate": agreement_count / total_questions if total_questions else 0,
        "average_round_count": total_rounds / total_questions if total_questions else 0,
        "round_count_histogram": dict(round_histogram),
        "per_agent_changes": {
            agent: {
                "changed_total": agent_changes_total[agent],
                "changed_to_correct": agent_changes_to_correct[agent],
                "changed_to_wrong": agent_changes_to_wrong[agent],
            }
            for agent in agent_total
        },
        "retrieval": {
            "average_calls_per_question": retrieval_total_calls / total_questions if total_questions else 0,
            "questions_with_retrieval_used": retrieval_question_count
        },
        "questions_all_agents_failed": questions_all_agents_failed,
        "questions_all_agents_agreed": questions_all_agents_agreed
    }

    final_result_path = os.path.join(save_dir, "final_result.json")
    with open(final_result_path, "w") as f:
        json.dump(final_result, f, indent=2)

    histogram_path = os.path.join(save_dir, "round_histogram.json")
    with open(histogram_path, "w") as f:
        json.dump(dict(round_histogram), f, indent=2)

    print(f"Aggregated metrics saved to {final_result_path}")
    print(f"Round histogram saved to {histogram_path}")

"""# Main"""

def run_experiment(exp_name):
    config = EXPERIMENTS[exp_name]

    llm = init_llm(provider=config["provider"], model=config["model"])
    agent_order = config["agent_order"]
    tie_break_strategy = config["tie_break_strategy"]
    strongest_agent = config["strongest_agent"]
    max_rounds = config["max_rounds"]

    agent_llms = {
        agent: llm for agent in agent_order + (["Judge"] if tie_break_strategy == "judge" else [])
    }

    exp_id = build_experiment_id(max_rounds, tie_break_strategy, strongest_agent, agent_llms, agent_order)
    DRIVE_ROOT = "/content/drive/My Drive/Agents_Project_Semantica/Results"
    SAVE_DIR = create_save_dir(os.path.join(DRIVE_ROOT, exp_id))

    runnable = create_runnable_graph(agent_order, agent_llms, make_agent_node, QAState, tie_break_strategy, strongest_agent, max_rounds)
    display_runnable(runnable)

    questions = get_questions(_DATA, num_questions=len(_DATA))
    results = run_batch_from_list(runnable, questions, agent_order, tie_break_strategy, strongest_agent, SAVE_DIR)

    compute_final_metrics(SAVE_DIR)

    return results

def run_all_experiments():
    for exp_name in EXPERIMENTS:
        print(f"\n====== Running {exp_name} ======")
        run_experiment(exp_name)

run_all_experiments()

"""Delete folders"""

# import shutil
# import os

# # List of folder name prefixes to remove
# prefixes = ['MaxRound', 'max_round']

# for folder in os.listdir():
#     if any(folder.startswith(prefix) for prefix in prefixes):
#         shutil.rmtree(folder)
#         print(f"Deleted folder: {folder}")

# import shutil

# # This will permanently delete the folder and everything inside
# shutil.rmtree('/content/drive/MyDrive/Agents_Project_Semantica')